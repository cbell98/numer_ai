{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTc0OJEJ77Sb"
      },
      "source": [
        "## Loading required libraries üìî and dataset üóÑÔ∏èüîΩ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dukzbOx5YPL2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26c49d8c-2867-4fcd-8419-bc30205d4490"
      },
      "source": [
        "# installing required libraries\n",
        "# numerapi, for facilitating data download and predictions uploading\n",
        "\n",
        "!pip install numerapi\n",
        "!pip install xgboost\n",
        "!pip install utils"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting numerapi\n",
            "  Downloading numerapi-2.14.0-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from numerapi) (2.27.1)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.9/dist-packages (from numerapi) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.9/dist-packages (from numerapi) (2.8.2)\n",
            "Requirement already satisfied: pandas>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from numerapi) (1.5.3)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.9/dist-packages (from numerapi) (8.1.3)\n",
            "Requirement already satisfied: tqdm>=4.29.1 in /usr/local/lib/python3.9/dist-packages (from numerapi) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.1.0->numerapi) (1.22.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil->numerapi) (1.16.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->numerapi) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->numerapi) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->numerapi) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->numerapi) (2022.12.7)\n",
            "Installing collected packages: numerapi\n",
            "Successfully installed numerapi-2.14.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.9/dist-packages (1.7.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from xgboost) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from xgboost) (1.10.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting utils\n",
            "  Downloading utils-1.0.1-py2.py3-none-any.whl (21 kB)\n",
            "Installing collected packages: utils\n",
            "Successfully installed utils-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3qA9k0VZ4Hj"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy\n",
        "from tqdm import tqdm\n",
        "from xgboost import XGBRegressor\n",
        "import gc\n",
        "import json\n",
        "from pathlib import Path\n",
        "from scipy.stats import skew\n",
        "\n",
        "from numerapi import NumerAPI\n",
        "import utils\n",
        "# from utils import (\n",
        "#     save_model,\n",
        "#     load_model,\n",
        "#     neutralize,\n",
        "#     get_biggest_change_features,\n",
        "#     validation_metrics,\n",
        "#     ERA_COL,\n",
        "#     DATA_TYPE_COL,\n",
        "#     TARGET_COL,\n",
        "#     EXAMPLE_PREDS_COL\n",
        "# )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrzPVfR6egjj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "4785cc16-cf25-4142-c7ee-5c40e900d635"
      },
      "source": [
        "# download all the things\n",
        "\n",
        "napi = NumerAPI()\n",
        "\n",
        "current_round = napi.get_current_round()\n",
        "\n",
        "# Tournament data changes every week so we specify the round in their name. Training\n",
        "# and validation data only change periodically, so no need to download them every time.\n",
        "print('Downloading dataset files...')\n",
        "\n",
        "Path(\"./v4\").mkdir(parents=False, exist_ok=True)\n",
        "napi.download_dataset(\"v4/train.parquet\")\n",
        "napi.download_dataset(\"v4/validation.parquet\")\n",
        "napi.download_dataset(\"v4/live.parquet\", f\"v4/live_{current_round}.parquet\")\n",
        "napi.download_dataset(\"v4/validation_example_preds.parquet\")\n",
        "napi.download_dataset(\"v4/features.json\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading dataset files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "v4/train.parquet: 1.16GB [00:25, 45.6MB/s]                            \n",
            "v4/validation.parquet: 1.18GB [00:26, 45.5MB/s]                            \n",
            "v4/live_467.parquet: 3.39MB [00:00, 7.73MB/s]                           \n",
            "v4/validation_example_preds.parquet: 58.3MB [00:01, 30.4MB/s]                            \n",
            "v4/features.json: 562kB [00:00, 2.17MB/s]                           \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'v4/features.json'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHdD3oxv8D5d"
      },
      "source": [
        "## Build Feature Set\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ERA_COL = \"era\"\n",
        "TARGET_COL = \"target_nomi_v4_20\"\n",
        "DATA_TYPE_COL = \"data_type\"\n",
        "EXAMPLE_PREDS_COL = \"example_preds\"\n",
        "\n",
        "MODEL_FOLDER = \"models\""
      ],
      "metadata": {
        "id": "Q4A2oCX0ArgU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHATa1jEq01J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a35afdcd-3e9e-48a2-f7a8-4de13722219a"
      },
      "source": [
        "print('Reading minimal training data')\n",
        "# read the feature metadata and get a feature set (or all the features)\n",
        "with open(\"v4/features.json\", \"r\") as f:\n",
        "    feature_metadata = json.load(f)\n",
        "# features = list(feature_metadata[\"feature_stats\"].keys()) # get all the features\n",
        "features = feature_metadata[\"feature_sets\"][\"small\"] # get the small feature set\n",
        "# features = feature_metadata[\"feature_sets\"][\"medium\"] # get the medium feature set\n",
        "# read in just those features along with era and target columns\n",
        "read_columns = features + [ERA_COL, DATA_TYPE_COL, TARGET_COL]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading minimal training data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxqczTVq8PR4"
      },
      "source": [
        "## Loading and exploring dataset into memory üñ•Ô∏è"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgodzImqq7z3"
      },
      "source": [
        "# note: sometimes when trying to read the downloaded data you get an error about invalid magic parquet bytes...\n",
        "# if so, delete the file and rerun the napi.download_dataset to fix the corrupted file\n",
        "training_data = pd.read_parquet('v4/train.parquet',\n",
        "                                columns=read_columns)\n",
        "validation_data = pd.read_parquet('v4/validation.parquet',\n",
        "                                  columns=read_columns)\n",
        "live_data = pd.read_parquet(f'v4/live_{current_round}.parquet',\n",
        "                                  columns=read_columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKGYq1Ce7MHX"
      },
      "source": [
        "# pare down the number of eras to every 4th era\n",
        "every_4th_era = training_data[ERA_COL].unique()[::4]\n",
        "training_data = training_data[training_data[ERA_COL].isin(every_4th_era)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyVjLKTy3tMx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "outputId": "a38bcbcd-e012-4733-ef3a-8eb8ef2eb61f"
      },
      "source": [
        "training_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  feature_bijou_penetrant_syringa  \\\n",
              "id                                                  \n",
              "n003bba8a98662e4                             0.00   \n",
              "n003bee128c2fcfc                             0.50   \n",
              "n0048ac83aff7194                             0.25   \n",
              "n00691bec80d3e02                             0.75   \n",
              "n00b8720a2fdc4f2                             0.00   \n",
              "\n",
              "                  feature_burning_phrygian_axinomancy  \\\n",
              "id                                                      \n",
              "n003bba8a98662e4                                 0.00   \n",
              "n003bee128c2fcfc                                 0.75   \n",
              "n0048ac83aff7194                                 0.25   \n",
              "n00691bec80d3e02                                 0.75   \n",
              "n00b8720a2fdc4f2                                 0.00   \n",
              "\n",
              "                  feature_censorial_leachier_rickshaw  \\\n",
              "id                                                      \n",
              "n003bba8a98662e4                                 0.50   \n",
              "n003bee128c2fcfc                                 0.75   \n",
              "n0048ac83aff7194                                 1.00   \n",
              "n00691bec80d3e02                                 0.00   \n",
              "n00b8720a2fdc4f2                                 0.50   \n",
              "\n",
              "                  feature_coastal_edible_whang  \\\n",
              "id                                               \n",
              "n003bba8a98662e4                          0.25   \n",
              "n003bee128c2fcfc                          0.75   \n",
              "n0048ac83aff7194                          0.75   \n",
              "n00691bec80d3e02                          0.00   \n",
              "n00b8720a2fdc4f2                          0.25   \n",
              "\n",
              "                  feature_coraciiform_sciurine_reef  \\\n",
              "id                                                    \n",
              "n003bba8a98662e4                               0.50   \n",
              "n003bee128c2fcfc                               0.50   \n",
              "n0048ac83aff7194                               1.00   \n",
              "n00691bec80d3e02                               0.75   \n",
              "n00b8720a2fdc4f2                               0.00   \n",
              "\n",
              "                  feature_corporatist_seborrheic_hopi  \\\n",
              "id                                                      \n",
              "n003bba8a98662e4                                 1.00   \n",
              "n003bee128c2fcfc                                 0.25   \n",
              "n0048ac83aff7194                                 0.75   \n",
              "n00691bec80d3e02                                 0.25   \n",
              "n00b8720a2fdc4f2                                 1.00   \n",
              "\n",
              "                  feature_cyclopedic_maestoso_daguerreotypist  \\\n",
              "id                                                              \n",
              "n003bba8a98662e4                                         0.50   \n",
              "n003bee128c2fcfc                                         0.50   \n",
              "n0048ac83aff7194                                         0.75   \n",
              "n00691bec80d3e02                                         0.25   \n",
              "n00b8720a2fdc4f2                                         0.25   \n",
              "\n",
              "                  feature_distressed_bloated_disquietude  \\\n",
              "id                                                         \n",
              "n003bba8a98662e4                                    0.50   \n",
              "n003bee128c2fcfc                                    0.75   \n",
              "n0048ac83aff7194                                    0.75   \n",
              "n00691bec80d3e02                                    0.00   \n",
              "n00b8720a2fdc4f2                                    0.25   \n",
              "\n",
              "                  feature_ecstatic_foundational_crinoidea  \\\n",
              "id                                                          \n",
              "n003bba8a98662e4                                     0.00   \n",
              "n003bee128c2fcfc                                     1.00   \n",
              "n0048ac83aff7194                                     0.75   \n",
              "n00691bec80d3e02                                     0.00   \n",
              "n00b8720a2fdc4f2                                     0.75   \n",
              "\n",
              "                  feature_elaborate_intimate_bor  ...  \\\n",
              "id                                                ...   \n",
              "n003bba8a98662e4                            0.50  ...   \n",
              "n003bee128c2fcfc                            0.75  ...   \n",
              "n0048ac83aff7194                            0.75  ...   \n",
              "n00691bec80d3e02                            0.00  ...   \n",
              "n00b8720a2fdc4f2                            0.25  ...   \n",
              "\n",
              "                  feature_undrilled_wheezier_countermand  \\\n",
              "id                                                         \n",
              "n003bba8a98662e4                                    0.75   \n",
              "n003bee128c2fcfc                                    0.25   \n",
              "n0048ac83aff7194                                    0.75   \n",
              "n00691bec80d3e02                                    0.50   \n",
              "n00b8720a2fdc4f2                                    0.25   \n",
              "\n",
              "                  feature_unpainted_censual_pinacoid  \\\n",
              "id                                                     \n",
              "n003bba8a98662e4                                 1.0   \n",
              "n003bee128c2fcfc                                 1.0   \n",
              "n0048ac83aff7194                                 0.0   \n",
              "n00691bec80d3e02                                 1.0   \n",
              "n00b8720a2fdc4f2                                 1.0   \n",
              "\n",
              "                  feature_unreproved_cultish_glioma  \\\n",
              "id                                                    \n",
              "n003bba8a98662e4                               1.00   \n",
              "n003bee128c2fcfc                               0.25   \n",
              "n0048ac83aff7194                               0.25   \n",
              "n00691bec80d3e02                               0.00   \n",
              "n00b8720a2fdc4f2                               0.00   \n",
              "\n",
              "                  feature_unsizable_ancestral_collocutor  \\\n",
              "id                                                         \n",
              "n003bba8a98662e4                                     0.5   \n",
              "n003bee128c2fcfc                                     0.5   \n",
              "n0048ac83aff7194                                     1.0   \n",
              "n00691bec80d3e02                                     0.5   \n",
              "n00b8720a2fdc4f2                                     0.0   \n",
              "\n",
              "                  feature_unsustaining_chewier_adnoun  \\\n",
              "id                                                      \n",
              "n003bba8a98662e4                                 0.25   \n",
              "n003bee128c2fcfc                                 1.00   \n",
              "n0048ac83aff7194                                 1.00   \n",
              "n00691bec80d3e02                                 0.00   \n",
              "n00b8720a2fdc4f2                                 0.25   \n",
              "\n",
              "                  feature_unswaddled_inenarrable_goody  \\\n",
              "id                                                       \n",
              "n003bba8a98662e4                                  0.25   \n",
              "n003bee128c2fcfc                                  0.75   \n",
              "n0048ac83aff7194                                  0.75   \n",
              "n00691bec80d3e02                                  0.50   \n",
              "n00b8720a2fdc4f2                                  1.00   \n",
              "\n",
              "                  feature_unventilated_sollar_bason   era  data_type  \\\n",
              "id                                                                     \n",
              "n003bba8a98662e4                               0.00  0001      train   \n",
              "n003bee128c2fcfc                               0.25  0001      train   \n",
              "n0048ac83aff7194                               1.00  0001      train   \n",
              "n00691bec80d3e02                               0.75  0001      train   \n",
              "n00b8720a2fdc4f2                               0.00  0001      train   \n",
              "\n",
              "                  target_nomi_v4_20  \n",
              "id                                   \n",
              "n003bba8a98662e4               0.25  \n",
              "n003bee128c2fcfc               0.75  \n",
              "n0048ac83aff7194               0.50  \n",
              "n00691bec80d3e02               0.75  \n",
              "n00b8720a2fdc4f2               0.75  \n",
              "\n",
              "[5 rows x 41 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-780ab32f-4555-45f2-8de6-cddce3e536e5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature_bijou_penetrant_syringa</th>\n",
              "      <th>feature_burning_phrygian_axinomancy</th>\n",
              "      <th>feature_censorial_leachier_rickshaw</th>\n",
              "      <th>feature_coastal_edible_whang</th>\n",
              "      <th>feature_coraciiform_sciurine_reef</th>\n",
              "      <th>feature_corporatist_seborrheic_hopi</th>\n",
              "      <th>feature_cyclopedic_maestoso_daguerreotypist</th>\n",
              "      <th>feature_distressed_bloated_disquietude</th>\n",
              "      <th>feature_ecstatic_foundational_crinoidea</th>\n",
              "      <th>feature_elaborate_intimate_bor</th>\n",
              "      <th>...</th>\n",
              "      <th>feature_undrilled_wheezier_countermand</th>\n",
              "      <th>feature_unpainted_censual_pinacoid</th>\n",
              "      <th>feature_unreproved_cultish_glioma</th>\n",
              "      <th>feature_unsizable_ancestral_collocutor</th>\n",
              "      <th>feature_unsustaining_chewier_adnoun</th>\n",
              "      <th>feature_unswaddled_inenarrable_goody</th>\n",
              "      <th>feature_unventilated_sollar_bason</th>\n",
              "      <th>era</th>\n",
              "      <th>data_type</th>\n",
              "      <th>target_nomi_v4_20</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>n003bba8a98662e4</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.50</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.50</td>\n",
              "      <td>...</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0001</td>\n",
              "      <td>train</td>\n",
              "      <td>0.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>n003bee128c2fcfc</th>\n",
              "      <td>0.50</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.75</td>\n",
              "      <td>...</td>\n",
              "      <td>0.25</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0001</td>\n",
              "      <td>train</td>\n",
              "      <td>0.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>n0048ac83aff7194</th>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>...</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.25</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0001</td>\n",
              "      <td>train</td>\n",
              "      <td>0.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>n00691bec80d3e02</th>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.50</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0001</td>\n",
              "      <td>train</td>\n",
              "      <td>0.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>n00b8720a2fdc4f2</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.25</td>\n",
              "      <td>...</td>\n",
              "      <td>0.25</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.25</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0001</td>\n",
              "      <td>train</td>\n",
              "      <td>0.75</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows √ó 41 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-780ab32f-4555-45f2-8de6-cddce3e536e5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-780ab32f-4555-45f2-8de6-cddce3e536e5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-780ab32f-4555-45f2-8de6-cddce3e536e5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFZAE25OyYNa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "outputId": "ed1c794b-72a1-4b67-d907-393bfe6697d7"
      },
      "source": [
        "live_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  feature_bijou_penetrant_syringa  \\\n",
              "id                                                  \n",
              "n00032303e32b0a2                             1.00   \n",
              "n0012a90672341dc                             1.00   \n",
              "n0015887848eec83                             0.25   \n",
              "n001dc25eee8945c                             1.00   \n",
              "n00219c6d7dcd08f                             0.00   \n",
              "\n",
              "                  feature_burning_phrygian_axinomancy  \\\n",
              "id                                                      \n",
              "n00032303e32b0a2                                 1.00   \n",
              "n0012a90672341dc                                 1.00   \n",
              "n0015887848eec83                                 1.00   \n",
              "n001dc25eee8945c                                 0.75   \n",
              "n00219c6d7dcd08f                                 0.00   \n",
              "\n",
              "                  feature_censorial_leachier_rickshaw  \\\n",
              "id                                                      \n",
              "n00032303e32b0a2                                 0.75   \n",
              "n0012a90672341dc                                 1.00   \n",
              "n0015887848eec83                                 1.00   \n",
              "n001dc25eee8945c                                 0.75   \n",
              "n00219c6d7dcd08f                                 0.00   \n",
              "\n",
              "                  feature_coastal_edible_whang  \\\n",
              "id                                               \n",
              "n00032303e32b0a2                          0.50   \n",
              "n0012a90672341dc                          0.75   \n",
              "n0015887848eec83                          1.00   \n",
              "n001dc25eee8945c                          1.00   \n",
              "n00219c6d7dcd08f                          0.00   \n",
              "\n",
              "                  feature_coraciiform_sciurine_reef  \\\n",
              "id                                                    \n",
              "n00032303e32b0a2                               0.50   \n",
              "n0012a90672341dc                               0.75   \n",
              "n0015887848eec83                               0.00   \n",
              "n001dc25eee8945c                               1.00   \n",
              "n00219c6d7dcd08f                               0.00   \n",
              "\n",
              "                  feature_corporatist_seborrheic_hopi  \\\n",
              "id                                                      \n",
              "n00032303e32b0a2                                 1.00   \n",
              "n0012a90672341dc                                 0.75   \n",
              "n0015887848eec83                                 0.00   \n",
              "n001dc25eee8945c                                 1.00   \n",
              "n00219c6d7dcd08f                                 0.75   \n",
              "\n",
              "                  feature_cyclopedic_maestoso_daguerreotypist  \\\n",
              "id                                                              \n",
              "n00032303e32b0a2                                         0.00   \n",
              "n0012a90672341dc                                         0.25   \n",
              "n0015887848eec83                                         0.25   \n",
              "n001dc25eee8945c                                         0.25   \n",
              "n00219c6d7dcd08f                                         0.75   \n",
              "\n",
              "                  feature_distressed_bloated_disquietude  \\\n",
              "id                                                         \n",
              "n00032303e32b0a2                                    1.00   \n",
              "n0012a90672341dc                                    1.00   \n",
              "n0015887848eec83                                    1.00   \n",
              "n001dc25eee8945c                                    0.25   \n",
              "n00219c6d7dcd08f                                    0.75   \n",
              "\n",
              "                  feature_ecstatic_foundational_crinoidea  \\\n",
              "id                                                          \n",
              "n00032303e32b0a2                                     0.00   \n",
              "n0012a90672341dc                                     1.00   \n",
              "n0015887848eec83                                     0.00   \n",
              "n001dc25eee8945c                                     0.75   \n",
              "n00219c6d7dcd08f                                     0.00   \n",
              "\n",
              "                  feature_elaborate_intimate_bor  ...  \\\n",
              "id                                                ...   \n",
              "n00032303e32b0a2                            1.00  ...   \n",
              "n0012a90672341dc                            1.00  ...   \n",
              "n0015887848eec83                            1.00  ...   \n",
              "n001dc25eee8945c                            0.25  ...   \n",
              "n00219c6d7dcd08f                            0.50  ...   \n",
              "\n",
              "                  feature_undrilled_wheezier_countermand  \\\n",
              "id                                                         \n",
              "n00032303e32b0a2                                    0.00   \n",
              "n0012a90672341dc                                    0.50   \n",
              "n0015887848eec83                                    0.00   \n",
              "n001dc25eee8945c                                    1.00   \n",
              "n00219c6d7dcd08f                                    0.25   \n",
              "\n",
              "                  feature_unpainted_censual_pinacoid  \\\n",
              "id                                                     \n",
              "n00032303e32b0a2                                0.00   \n",
              "n0012a90672341dc                                0.50   \n",
              "n0015887848eec83                                0.25   \n",
              "n001dc25eee8945c                                0.50   \n",
              "n00219c6d7dcd08f                                0.00   \n",
              "\n",
              "                  feature_unreproved_cultish_glioma  \\\n",
              "id                                                    \n",
              "n00032303e32b0a2                               0.50   \n",
              "n0012a90672341dc                               0.50   \n",
              "n0015887848eec83                               1.00   \n",
              "n001dc25eee8945c                               0.00   \n",
              "n00219c6d7dcd08f                               0.75   \n",
              "\n",
              "                  feature_unsizable_ancestral_collocutor  \\\n",
              "id                                                         \n",
              "n00032303e32b0a2                                    0.50   \n",
              "n0012a90672341dc                                    0.75   \n",
              "n0015887848eec83                                    0.00   \n",
              "n001dc25eee8945c                                    1.00   \n",
              "n00219c6d7dcd08f                                    0.00   \n",
              "\n",
              "                  feature_unsustaining_chewier_adnoun  \\\n",
              "id                                                      \n",
              "n00032303e32b0a2                                 0.50   \n",
              "n0012a90672341dc                                 1.00   \n",
              "n0015887848eec83                                 1.00   \n",
              "n001dc25eee8945c                                 0.75   \n",
              "n00219c6d7dcd08f                                 0.00   \n",
              "\n",
              "                  feature_unswaddled_inenarrable_goody  \\\n",
              "id                                                       \n",
              "n00032303e32b0a2                                  0.75   \n",
              "n0012a90672341dc                                  0.00   \n",
              "n0015887848eec83                                  0.25   \n",
              "n001dc25eee8945c                                  0.50   \n",
              "n00219c6d7dcd08f                                  1.00   \n",
              "\n",
              "                  feature_unventilated_sollar_bason  era  data_type  \\\n",
              "id                                                                    \n",
              "n00032303e32b0a2                               1.00    X       live   \n",
              "n0012a90672341dc                               0.25    X       live   \n",
              "n0015887848eec83                               0.00    X       live   \n",
              "n001dc25eee8945c                               0.75    X       live   \n",
              "n00219c6d7dcd08f                               0.25    X       live   \n",
              "\n",
              "                  target_nomi_v4_20  \n",
              "id                                   \n",
              "n00032303e32b0a2                NaN  \n",
              "n0012a90672341dc                NaN  \n",
              "n0015887848eec83                NaN  \n",
              "n001dc25eee8945c                NaN  \n",
              "n00219c6d7dcd08f                NaN  \n",
              "\n",
              "[5 rows x 41 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-90e21a81-a4f3-4193-8893-1e5c1718285f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature_bijou_penetrant_syringa</th>\n",
              "      <th>feature_burning_phrygian_axinomancy</th>\n",
              "      <th>feature_censorial_leachier_rickshaw</th>\n",
              "      <th>feature_coastal_edible_whang</th>\n",
              "      <th>feature_coraciiform_sciurine_reef</th>\n",
              "      <th>feature_corporatist_seborrheic_hopi</th>\n",
              "      <th>feature_cyclopedic_maestoso_daguerreotypist</th>\n",
              "      <th>feature_distressed_bloated_disquietude</th>\n",
              "      <th>feature_ecstatic_foundational_crinoidea</th>\n",
              "      <th>feature_elaborate_intimate_bor</th>\n",
              "      <th>...</th>\n",
              "      <th>feature_undrilled_wheezier_countermand</th>\n",
              "      <th>feature_unpainted_censual_pinacoid</th>\n",
              "      <th>feature_unreproved_cultish_glioma</th>\n",
              "      <th>feature_unsizable_ancestral_collocutor</th>\n",
              "      <th>feature_unsustaining_chewier_adnoun</th>\n",
              "      <th>feature_unswaddled_inenarrable_goody</th>\n",
              "      <th>feature_unventilated_sollar_bason</th>\n",
              "      <th>era</th>\n",
              "      <th>data_type</th>\n",
              "      <th>target_nomi_v4_20</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>n00032303e32b0a2</th>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.00</td>\n",
              "      <td>X</td>\n",
              "      <td>live</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>n0012a90672341dc</th>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.25</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.25</td>\n",
              "      <td>X</td>\n",
              "      <td>live</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>n0015887848eec83</th>\n",
              "      <td>0.25</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.25</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.25</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.00</td>\n",
              "      <td>X</td>\n",
              "      <td>live</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>n001dc25eee8945c</th>\n",
              "      <td>1.00</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.25</td>\n",
              "      <td>...</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.75</td>\n",
              "      <td>X</td>\n",
              "      <td>live</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>n00219c6d7dcd08f</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.50</td>\n",
              "      <td>...</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.25</td>\n",
              "      <td>X</td>\n",
              "      <td>live</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows √ó 41 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-90e21a81-a4f3-4193-8893-1e5c1718285f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-90e21a81-a4f3-4193-8893-1e5c1718285f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-90e21a81-a4f3-4193-8893-1e5c1718285f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# getting the per era correlation of each feature vs the target\n",
        "all_feature_corrs = training_data.groupby(ERA_COL).apply(\n",
        "    lambda era: era[features].corrwith(era[TARGET_COL])\n",
        ")"
      ],
      "metadata": {
        "id": "jQYjQ_RnB6p7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# helper function\n",
        "\n",
        "def get_biggest_change_features(corrs, n):\n",
        "    all_eras = corrs.index.sort_values()\n",
        "    h1_eras = all_eras[: len(all_eras) // 2]\n",
        "    h2_eras = all_eras[len(all_eras) // 2 :]\n",
        "\n",
        "    h1_corr_means = corrs.loc[h1_eras, :].mean()\n",
        "    h2_corr_means = corrs.loc[h2_eras, :].mean()\n",
        "\n",
        "    corr_diffs = h2_corr_means - h1_corr_means\n",
        "    worst_n = corr_diffs.abs().sort_values(ascending=False).head(n).index.tolist()\n",
        "    return worst_n"
      ],
      "metadata": {
        "id": "_KHfYaC4CGiE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# find the riskiest features by comparing their correlation vs\n",
        "# the target in each half of training data; we'll use these later\n",
        "riskiest_features = get_biggest_change_features(all_feature_corrs, 50)"
      ],
      "metadata": {
        "id": "hrK01S7mB_Ku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# \"garbage collection\" (gc) gets rid of unused data and frees up memory\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "sM8_H6AxB_TS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfe9ca02-c471-46c5-a1cf-5d29f038a3ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwdqS642BP-u"
      },
      "source": [
        "## Training our model ü§ñ‚öôÔ∏è\n",
        "\n",
        "This is where most of tweaking will happen. You can add more model in your pipeline simply by changing your model and data pipeline suited for that architecture."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper Functions\n",
        "\n",
        "def save_prediction(df, name):\n",
        "    try:\n",
        "        Path(PREDICTION_FILES_FOLDER).mkdir(exist_ok=True, parents=True)\n",
        "    except Exception as ex:\n",
        "        pass\n",
        "    df.to_csv(f\"{PREDICTION_FILES_FOLDER}/{name}.csv\", index=True)\n",
        "\n",
        "\n",
        "def save_model(model, name):\n",
        "    try:\n",
        "        Path(MODEL_FOLDER).mkdir(exist_ok=True, parents=True)\n",
        "    except Exception as ex:\n",
        "        pass\n",
        "    pd.to_pickle(model, f\"{MODEL_FOLDER}/{name}.pkl\")\n",
        "\n",
        "\n",
        "def load_model(name):\n",
        "    path = Path(f\"{MODEL_FOLDER}/{name}.pkl\")\n",
        "    if path.is_file():\n",
        "        model = pd.read_pickle(f\"{MODEL_FOLDER}/{name}.pkl\")\n",
        "    else:\n",
        "        model = False\n",
        "    return model"
      ],
      "metadata": {
        "id": "e9EcQGomCtXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGCEWaizehA9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15ec5203-79b2-4fcc-c814-66c9e1687c84"
      },
      "source": [
        "model_name = f\"model_target\"\n",
        "print(f\"Checking for existing model '{model_name}'\")\n",
        "model = load_model(model_name)\n",
        "if not model:\n",
        "    print(f\"model not found, creating new one\")\n",
        "    params = {\"n_estimators\": 2000,\n",
        "              \"learning_rate\": 0.01,\n",
        "              \"max_depth\": 5,\n",
        "              \"colsample_bytree\": 0.1}\n",
        "\n",
        "    model = XGBRegressor(**params)\n",
        "\n",
        "    # train on all of train and save the model so we don't have to train next time\n",
        "    model.fit(training_data.filter(like='feature_', axis='columns'),\n",
        "              training_data[TARGET_COL])\n",
        "    print(f\"saving new model: {model_name}\")\n",
        "    save_model(model, model_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking for existing model 'model_target'\n",
            "model not found, creating new one\n",
            "saving new model: model_target\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()"
      ],
      "metadata": {
        "id": "uAbQoIyBEHJV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d8fd2b5-677c-4d17-bfe8-19abb5cc4714"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "37"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nans_per_col = live_data[live_data[\"data_type\"] == \"live\"][features].isna().sum()\n",
        "\n",
        "# check for nans and fill nans\n",
        "if nans_per_col.any():\n",
        "    total_rows = len(live_data[live_data[\"data_type\"] == \"live\"])\n",
        "    print(f\"Number of nans per column this week: {nans_per_col[nans_per_col > 0]}\")\n",
        "    print(f\"out of {total_rows} total rows\")\n",
        "    print(f\"filling nans with 0.5\")\n",
        "    live_data.loc[:, features] = live_data.loc[:, features].fillna(0.5)\n",
        "\n",
        "else:\n",
        "    print(\"No nans in the features this week!\")"
      ],
      "metadata": {
        "id": "MU7KUYxlEP2m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b45272f-8375-4f45-8656-24239a600fbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No nans in the features this week!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# double check the feature that the model expects vs what is available to prevent our\n",
        "# pipeline from failing if Numerai adds more data and we don't have time to retrain!\n",
        "model_expected_features = model.get_booster().get_score(importance_type='gain')\n",
        "if set(model_expected_features) != set(features):\n",
        "    print(f\"New features are available! Might want to retrain model {model_name}.\")\n",
        "validation_data.loc[:, f\"preds_{model_name}\"] = model.predict(\n",
        "    validation_data.loc[:, model_expected_features])\n",
        "live_data.loc[:, f\"preds_{model_name}\"] = model.predict(\n",
        "    live_data.loc[:, model_expected_features])"
      ],
      "metadata": {
        "id": "uS1oA1tmEQAe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a519bcd7-6f52-4ff2-ba16-3c839e649866"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-65d97dab2657>:7: FutureWarning: Passing a dict as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
            "  validation_data.loc[:, model_expected_features])\n",
            "<ipython-input-18-65d97dab2657>:9: FutureWarning: Passing a dict as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
            "  live_data.loc[:, model_expected_features])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()"
      ],
      "metadata": {
        "id": "w1Ie0N2BEi6Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ff97192-c11b-4020-8557-d87b9ea8af2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neutralize"
      ],
      "metadata": {
        "id": "S2bWN_itEvF0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper function\n",
        "\n",
        "def neutralize(\n",
        "    df, columns, neutralizers=None, proportion=1.0, normalize=True, era_col=\"era\", verbose=False\n",
        "):\n",
        "    if neutralizers is None:\n",
        "        neutralizers = []\n",
        "    unique_eras = df[era_col].unique()\n",
        "    computed = []\n",
        "    if verbose:\n",
        "        iterator = tqdm(unique_eras)\n",
        "    else:\n",
        "        iterator = unique_eras\n",
        "    for u in iterator:\n",
        "        df_era = df[df[era_col] == u]\n",
        "        scores = df_era[columns].values\n",
        "        if normalize:\n",
        "            scores2 = []\n",
        "            for x in scores.T:\n",
        "                x = (scipy.stats.rankdata(x, method=\"ordinal\") - 0.5) / len(x)\n",
        "                x = scipy.stats.norm.ppf(x)\n",
        "                scores2.append(x)\n",
        "            scores = np.array(scores2).T\n",
        "        exposures = df_era[neutralizers].values\n",
        "\n",
        "        scores -= proportion * exposures.dot(\n",
        "            np.linalg.pinv(exposures.astype(np.float32), rcond=1e-6).dot(\n",
        "                scores.astype(np.float32)\n",
        "            )\n",
        "        )\n",
        "\n",
        "        scores /= scores.std(ddof=0)\n",
        "\n",
        "        computed.append(scores)\n",
        "\n",
        "    return pd.DataFrame(np.concatenate(computed), columns=columns, index=df.index)"
      ],
      "metadata": {
        "id": "WmbasVe2E4Ap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# neutralize our predictions to the riskiest features\n",
        "validation_data[f\"preds_{model_name}_neutral_riskiest_50\"] = neutralize(\n",
        "    df=validation_data,\n",
        "    columns=[f\"preds_{model_name}\"],\n",
        "    neutralizers=riskiest_features,\n",
        "    proportion=1.0,\n",
        "    normalize=True,\n",
        "    era_col=ERA_COL\n",
        ")\n",
        "\n",
        "live_data[f\"preds_{model_name}_neutral_riskiest_50\"] = neutralize(\n",
        "    df=live_data,\n",
        "    columns=[f\"preds_{model_name}\"],\n",
        "    neutralizers=riskiest_features,\n",
        "    proportion=1.0,\n",
        "    normalize=True,\n",
        "    era_col=ERA_COL\n",
        ")"
      ],
      "metadata": {
        "id": "Kd5kRxHHE4WP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1ZceR9FAaPa"
      },
      "source": [
        "## Predictions. Evaluation. ‚û°Ô∏è"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAAMLN13eg9z"
      },
      "source": [
        "model_to_submit = f\"preds_{model_name}_neutral_riskiest_50\"\n",
        "\n",
        "# rename best model to \"prediction\" and rank from 0 to 1 to meet upload requirements\n",
        "validation_data[\"prediction\"] = validation_data[model_to_submit].rank(pct=True)\n",
        "live_data[\"prediction\"] = live_data[model_to_submit].rank(pct=True)\n",
        "validation_data[\"prediction\"].to_csv(f\"validation_predictions_{current_round}.csv\")\n",
        "live_data[\"prediction\"].to_csv(f\"live_predictions_{current_round}.csv\")\n",
        "\n",
        "validation_preds = pd.read_parquet('v4/validation_example_preds.parquet')\n",
        "validation_data[EXAMPLE_PREDS_COL] = validation_preds[\"prediction\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper Functions\n",
        "\n",
        "def neutralize_series(series, by, proportion=1.0):\n",
        "    scores = series.values.reshape(-1, 1)\n",
        "    exposures = by.values.reshape(-1, 1)\n",
        "\n",
        "    # this line makes series neutral to a constant column so that it's centered and for sure gets corr 0 with exposures\n",
        "    exposures = np.hstack(\n",
        "        (exposures, np.array([np.mean(series)] * len(exposures)).reshape(-1, 1))\n",
        "    )\n",
        "\n",
        "    correction = proportion * (\n",
        "        exposures.dot(np.linalg.lstsq(exposures, scores, rcond=None)[0])\n",
        "    )\n",
        "    corrected_scores = scores - correction\n",
        "    neutralized = pd.Series(corrected_scores.ravel(), index=series.index)\n",
        "    return neutralized\n",
        "\n",
        "\n",
        "def unif(df):\n",
        "    x = (df.rank(method=\"first\") - 0.5) / len(df)\n",
        "    return pd.Series(x, index=df.index)\n",
        "\n",
        "\n",
        "def get_feature_neutral_mean(\n",
        "    df, prediction_col, target_col, features_for_neutralization=None\n",
        "):\n",
        "    if features_for_neutralization is None:\n",
        "        features_for_neutralization = [c for c in df.columns if c.startswith(\"feature\")]\n",
        "    df.loc[:, \"neutral_sub\"] = neutralize(\n",
        "        df, [prediction_col], features_for_neutralization\n",
        "    )[prediction_col]\n",
        "    scores = (\n",
        "        df.groupby(\"era\")\n",
        "        .apply(lambda x: (unif(x[\"neutral_sub\"]).corr(x[target_col])))\n",
        "        .mean()\n",
        "    )\n",
        "    return np.mean(scores)\n",
        "\n",
        "\n",
        "def get_feature_neutral_mean_tb_era(\n",
        "    df, prediction_col, target_col, tb, features_for_neutralization=None\n",
        "):\n",
        "    if features_for_neutralization is None:\n",
        "        features_for_neutralization = [c for c in df.columns if c.startswith(\"feature\")]\n",
        "    temp_df = df.reset_index(\n",
        "        drop=True\n",
        "    ).copy()  # Reset index due to use of argsort later\n",
        "    temp_df.loc[:, \"neutral_sub\"] = neutralize(\n",
        "        temp_df, [prediction_col], features_for_neutralization\n",
        "    )[prediction_col]\n",
        "    temp_df_argsort = temp_df.loc[:, \"neutral_sub\"].argsort()\n",
        "    temp_df_tb_idx = pd.concat([temp_df_argsort.iloc[:tb], temp_df_argsort.iloc[-tb:]])\n",
        "    temp_df_tb = temp_df.loc[temp_df_tb_idx]\n",
        "    tb_fnc = unif(temp_df_tb[\"neutral_sub\"]).corr(temp_df_tb[target_col])\n",
        "    return tb_fnc\n",
        "\n",
        "\n",
        "def fast_score_by_date(df, columns, target, tb=None, era_col=\"era\"):\n",
        "    unique_eras = df[era_col].unique()\n",
        "    computed = []\n",
        "    for u in unique_eras:\n",
        "        df_era = df[df[era_col] == u]\n",
        "        era_pred = np.float64(df_era[columns].values.T)\n",
        "        era_target = np.float64(df_era[target].values.T)\n",
        "\n",
        "        if tb is None:\n",
        "            ccs = np.corrcoef(era_target, era_pred)[0, 1:]\n",
        "        else:\n",
        "            tbidx = np.argsort(era_pred, axis=1)\n",
        "            tbidx = np.concatenate([tbidx[:, :tb], tbidx[:, -tb:]], axis=1)\n",
        "            ccs = [\n",
        "                np.corrcoef(era_target[tmpidx], tmppred[tmpidx])[0, 1]\n",
        "                for tmpidx, tmppred in zip(tbidx, era_pred)\n",
        "            ]\n",
        "            ccs = np.array(ccs)\n",
        "\n",
        "        computed.append(ccs)\n",
        "\n",
        "    return pd.DataFrame(np.array(computed), columns=columns, index=df[era_col].unique())\n",
        "\n",
        "\n",
        "def exposure_dissimilarity_per_era(df, prediction_col, example_col, feature_cols=None):\n",
        "    if feature_cols is None:\n",
        "        feature_cols = [c for c in df.columns if c.startswith(\"feature\")]\n",
        "    u = df.loc[:, feature_cols].corrwith(df[prediction_col])\n",
        "    e = df.loc[:, feature_cols].corrwith(df[example_col])\n",
        "    return 1 - (np.dot(u, e) / np.dot(e, e))\n",
        "\n",
        "\n",
        "def validation_metrics(\n",
        "    validation_data,\n",
        "    pred_cols,\n",
        "    example_col,\n",
        "    fast_mode=False,\n",
        "    target_col=TARGET_COL,\n",
        "    features_for_neutralization=None,\n",
        "):\n",
        "    validation_stats = pd.DataFrame()\n",
        "    feature_cols = [c for c in validation_data if c.startswith(\"feature_\")]\n",
        "    for pred_col in pred_cols:\n",
        "        # Check the per-era correlations on the validation set (out of sample)\n",
        "        validation_correlations = validation_data.groupby(ERA_COL).apply(\n",
        "            lambda d: unif(d[pred_col]).corr(d[target_col])\n",
        "        )\n",
        "\n",
        "        mean = validation_correlations.mean()\n",
        "        std = validation_correlations.std(ddof=0)\n",
        "        sharpe = mean / std\n",
        "\n",
        "        validation_stats.loc[\"mean\", pred_col] = mean\n",
        "        validation_stats.loc[\"std\", pred_col] = std\n",
        "        validation_stats.loc[\"sharpe\", pred_col] = sharpe\n",
        "\n",
        "        rolling_max = (\n",
        "            (validation_correlations + 1)\n",
        "            .cumprod()\n",
        "            .rolling(window=9000, min_periods=1)  # arbitrarily large\n",
        "            .max()\n",
        "        )\n",
        "        daily_value = (validation_correlations + 1).cumprod()\n",
        "        max_drawdown = -((rolling_max - daily_value) / rolling_max).max()\n",
        "        validation_stats.loc[\"max_drawdown\", pred_col] = max_drawdown\n",
        "\n",
        "        payout_scores = validation_correlations.clip(-0.25, 0.25)\n",
        "        payout_daily_value = (payout_scores + 1).cumprod()\n",
        "\n",
        "        apy = (\n",
        "            ((payout_daily_value.dropna().iloc[-1]) ** (1 / len(payout_scores)))\n",
        "            ** 49  # 52 weeks of compounding minus 3 for stake compounding lag\n",
        "            - 1\n",
        "        ) * 100\n",
        "\n",
        "        validation_stats.loc[\"apy\", pred_col] = apy\n",
        "\n",
        "        if not fast_mode:\n",
        "            # Check the feature exposure of your validation predictions\n",
        "            max_per_era = validation_data.groupby(ERA_COL).apply(\n",
        "                lambda d: d[feature_cols].corrwith(d[pred_col]).abs().max()\n",
        "            )\n",
        "            max_feature_exposure = max_per_era.mean()\n",
        "            validation_stats.loc[\n",
        "                \"max_feature_exposure\", pred_col\n",
        "            ] = max_feature_exposure\n",
        "\n",
        "            # Check feature neutral mean\n",
        "            feature_neutral_mean = get_feature_neutral_mean(\n",
        "                validation_data, pred_col, target_col, features_for_neutralization\n",
        "            )\n",
        "            validation_stats.loc[\n",
        "                \"feature_neutral_mean\", pred_col\n",
        "            ] = feature_neutral_mean\n",
        "\n",
        "            # Check TB200 feature neutral mean\n",
        "            tb200_feature_neutral_mean_era = validation_data.groupby(ERA_COL).apply(\n",
        "                lambda df: get_feature_neutral_mean_tb_era(\n",
        "                    df, pred_col, target_col, 200, features_for_neutralization\n",
        "                )\n",
        "            )\n",
        "            validation_stats.loc[\n",
        "                \"tb200_feature_neutral_mean\", pred_col\n",
        "            ] = tb200_feature_neutral_mean_era.mean()\n",
        "\n",
        "            # Check top and bottom 200 metrics (TB200)\n",
        "            tb200_validation_correlations = fast_score_by_date(\n",
        "                validation_data, [pred_col], target_col, tb=200, era_col=ERA_COL\n",
        "            )\n",
        "\n",
        "            tb200_mean = tb200_validation_correlations.mean()[pred_col]\n",
        "            tb200_std = tb200_validation_correlations.std(ddof=0)[pred_col]\n",
        "            tb200_sharpe = tb200_mean / tb200_std\n",
        "\n",
        "            validation_stats.loc[\"tb200_mean\", pred_col] = tb200_mean\n",
        "            validation_stats.loc[\"tb200_std\", pred_col] = tb200_std\n",
        "            validation_stats.loc[\"tb200_sharpe\", pred_col] = tb200_sharpe\n",
        "\n",
        "        # MMC over validation\n",
        "        mmc_scores = []\n",
        "        corr_scores = []\n",
        "        for _, x in validation_data.groupby(ERA_COL):\n",
        "            series = neutralize_series(unif(x[pred_col]), (x[example_col]))\n",
        "            mmc_scores.append(np.cov(series, x[target_col])[0, 1] / (0.29**2))\n",
        "            corr_scores.append(unif(x[pred_col]).corr(x[target_col]))\n",
        "\n",
        "        val_mmc_mean = np.mean(mmc_scores)\n",
        "        val_mmc_std = np.std(mmc_scores)\n",
        "        corr_plus_mmcs = [c + m for c, m in zip(corr_scores, mmc_scores)]\n",
        "        corr_plus_mmc_sharpe = np.mean(corr_plus_mmcs) / np.std(corr_plus_mmcs)\n",
        "\n",
        "        validation_stats.loc[\"mmc_mean\", pred_col] = val_mmc_mean\n",
        "        validation_stats.loc[\"corr_plus_mmc_sharpe\", pred_col] = corr_plus_mmc_sharpe\n",
        "\n",
        "        # Check correlation with example predictions\n",
        "        per_era_corrs = validation_data.groupby(ERA_COL).apply(\n",
        "            lambda d: unif(d[pred_col]).corr(unif(d[example_col]))\n",
        "        )\n",
        "        corr_with_example_preds = per_era_corrs.mean()\n",
        "        validation_stats.loc[\n",
        "            \"corr_with_example_preds\", pred_col\n",
        "        ] = corr_with_example_preds\n",
        "\n",
        "        # Check exposure dissimilarity per era\n",
        "        tdf = validation_data.groupby(ERA_COL).apply(\n",
        "            lambda df: exposure_dissimilarity_per_era(\n",
        "                df, pred_col, example_col, feature_cols\n",
        "            )\n",
        "        )\n",
        "        validation_stats.loc[\"exposure_dissimilarity_mean\", pred_col] = tdf.mean()\n",
        "\n",
        "    # .transpose so that stats are columns and the model_name is the row\n",
        "    return validation_stats.transpose()"
      ],
      "metadata": {
        "id": "jiwIKfs5HTBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2r269Xaeo9_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acd15197-3cae-4c81-ee9b-e33228a165a4"
      },
      "source": [
        "# get some stats about each of our models to compare...\n",
        "# fast_mode=True so that we skip some of the stats that are slower to calculate\n",
        "validation_stats = validation_metrics(validation_data, [model_to_submit, f\"preds_{model_name}\"], example_col=EXAMPLE_PREDS_COL, fast_mode=True, target_col=TARGET_COL)\n",
        "print(validation_stats[[\"mean\", \"sharpe\"]].to_markdown())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|                                        |      mean |   sharpe |\n",
            "|:---------------------------------------|----------:|---------:|\n",
            "| preds_model_target_neutral_riskiest_50 | 0.0130173 | 0.643508 |\n",
            "| preds_model_target                     | 0.0175353 | 0.630208 |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWjIbe_emZtd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad1e3a15-e134-4cd0-adf3-ad4335312435"
      },
      "source": [
        "print(f'''\n",
        "Done! Next steps:\n",
        "    1. Go to numer.ai/tournament (make sure you have an account)\n",
        "    2. Submit validation_predictions_{current_round}.csv to the diagnostics tool\n",
        "    3. Submit tournament_predictions_{current_round}.csv to the \"Upload Predictions\" button\n",
        "''')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Done! Next steps:\n",
            "    1. Go to numer.ai/tournament (make sure you have an account)\n",
            "    2. Submit validation_predictions_467.csv to the diagnostics tool\n",
            "    3. Submit tournament_predictions_467.csv to the \"Upload Predictions\" button\n",
            "\n"
          ]
        }
      ]
    }
  ]
}